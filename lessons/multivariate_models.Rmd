---
title: "Multivariate models"
output: html_document
---

The goal of this lesson are to introduce multivariate ordination analyses.

## Readings
* Chapters 5 and 6 of *Numerical Ecology with R*

## Online Docs
* [The Ordination Webpage](http://ordination.okstate.edu/)
    - great for term definitions, layman's explanation of how the methods
    differ, and how ecologists should interpret
* [Vegan: an introduction to ordination](http://cran.r-project.org/web/packages/vegan/vignettes/intro-vegan.pdf)
    - A brief demonstration of an ordination analysis in the R package vegan
* [Multivariate Analysis of Ecological Communities in R: vegan tutorial](http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf)
    - A more thorough  of ordination in the R package vegan

##Outline
* Overview of ordination methods
* Create a community matrix.
* Indirect or Unconstrained Ordination
    - Principle Components Analysis (PCA)
    - Correspondence Analysis (CA) 
    - Detrended Correspondence Analysis (DCA)
    - Non-metric Multidimensional Scaling (NMDS)
* Direct or Constrained Ordination
    - Redundancy Analysis (RDA)
    - Canonical Correspondence Analysis (CCA)
    - Hypothesis Testing
    - Model Comparison
    - Variance partitioning

## Overview of ordination methods

There are generally considered to be two types of ordination. 

1. Indirect or unconstrained ordination in which only a single matrix is analyzed
2. Direct or constrained ordination in which one matrix is used to explain the 
variance of another matrix. 

Today we will demonstrate both types. In general, ordination is frequently used
when exploring patterns in datasets graphically; however, it can also be used 
to carry out hypothesis testing. 

The term ordination derives from the idea to ordinate or put things into order.
With ordination approaches were are attempting to take a high-dimensional 
data matrix and explain its patterns with a small number of axes. 

Despite their sometimes terrifying names ordination has a close kinship with 
multiple regression. One key difference is that the response variable is 
multivariate rather than univariate; however, with many approaches the underlying
algebra is very similar between regression and ordination.

The [Ordination methods table](./ordination_methods_table.html)
provides a simple overview for some of the more popular ordination approaches. 

This [presentation](./community_structure_slides_with_notes.pdf) by 
[Abel Valdivia](http://www.unc.edu/~abelvald/) provides a review of the types of
ordination and provides examples of their graphical output. 

Additionally this [key](http://ordination.okstate.edu/key.htm) created by Mike
Palmer provides a decision tree that can help to guide your choice of methods.

```{r setup, echo=FALSE}
# setup the R enviornment for kniting markdown doc properly
library(knitr)
opts_knit$set(root.dir='../')
```

## Create a community matrix
```{r}
# load relevant packages and code for today's lesson
library(vegan)
library(dummies)
source('./scripts/utility_functions.R')

# load data
tree = read.csv('./data/treedata.csv')
tree = subset(tree, plotsize == 1000)

# construct a unique plot id
tree$plotID = paste(tree$plotID, tree$date,
                    tree$utme, tree$utmn, sep='_')

# create a community site x species matrix by summing species cover values
# we can do this with a for loop but it take a while to run
uni_sp = unique(tree$spcode)
uni_site = unique(tree$plotID)
```
```{r, eval=FALSE}
comm = matrix(NA, ncol=length(uni_sp), nrow=length(uni_site))
colnames(comm) = uni_sp
rownames(comm) = uni_site
for(i in seq_along(uni_sp)) {
    for(j in seq_along(uni_site)) {
        comm[j , i] = mean(tree$cover[tree$spcode == uni_sp[i] &
                          tree$plotID == uni_site[j]])
    }
}
comm[1:5, 1:5]
```
```{r}
# alternatively we can use a tapply function 
comm = tapply(tree$cover, INDEX = list(tree$plotID, tree$spcode), mean)
# examine the community matrix
comm[1:5, 1:5]
# replace the NAs with zeros
comm = ifelse(is.na(comm), 0, comm)
comm[1:5, 1:5]
# visually explore the cover variable between species and sites
uni_sp = unique(tree$spcode)
sp_sum = apply(comm, 2, sum)
site_sum = apply(comm, 1, sum)
par(mfrow=c(2,2))
hist(sp_sum)
col = colorRamp(c('red', 'orange', 'blue'))
sp_cols = col(length(uni_sp))
plot(sp_sum[order(sp_sum, decreasing=T)], type='o', col='red', lwd=2,
     xlab='Sp Rank', ylab='Sum Cover')
hist(site_sum)
plot(site_sum[order(site_sum, decreasing=T)], type='o', col='red', lwd=2,
     xlab='Site Rank', ylab='Sum Cover')
par(mfrow=c(1,1))
```

## Create an explanatory matrix
```{r}
head(tree)
cols_to_keep = c('utme', 'utmn', 'elev', 'tci', 'streamdist', 'disturb', 'beers')
env = aggregate(tree[ , cols_to_keep], by = list(tree$plotID), function(x) x[1])
head(env)
# drop first column and make it a row name
row.names(env) = env[ , 1]
env = env[ , -1]
head(env)

# before we can use this explanatory matrix we need to check 
# that its rows are in the same order as our response matrix

all.equal(rownames(comm), rownames(env))

# now that we've completed that check we can rename the rows to something 
# more manageable

rownames(comm) = 1:nrow(comm)
rownames(env) = 1:nrow(env)

# this should return a TRUE so we're ready for some analyses
```

## Indirect or Unconstrained Ordination
### Principle Components Analysis (PCA)

Principle Components Analysis (PCA) is a useful tool for either

1. examining correlations between the columns of a matrix
2. potentially reducing the set of explanatory variables included in model

```{r}
# PCA on enviornmental data
# must drop categorical variable for PCA on standardized variables
summary(env)
env_pca = rda(env[ , names(env) != 'disturb'], scale=TRUE)
env_pca
names(env_pca)
sum(1.6166, 0.9485, 0.8495, 0.5854)

plot(env_pca, display=c('sp'))
cleanplot.pca(env_pca)

tree_pca = rda(comm, scale=TRUE)
plot(tree_pca)
biplot(tree_pca)
cleanplot.pca(tree_pca)
# p120-121 of Numerical Ecology in R:
# Scaling 1 = distance biplot: the eigenvectors are scaled to unit length. (1)
# Distances among objects in the biplot are approximations of their
# Euclidean distances in multidimensional space. (2) The angles among
# descriptor vectors are meaningless.
# Scaling 2 = correlation biplot: each eigenvector is scaled to the square root of
# its eigenvalue. (1) Distances among objects in the biplot are not approximations
# of their Euclidean distances in multidimensional space. (2) The angles
# between descriptors in the biplot reflect their correlations.
```

### Correspondance Anlysis (CA), Detrended Coresspondance Analysis (DCA), and NMDS

```{r, eval=FALSE}
# each of these different indirect ordination approaches
# has different strenghts and weaknesses
# Correspondance analysis  (CA) examines differences on weighted
# averages of the columns (i.e., species in this case)
tree_ca = cca(comm)

# Detrended correspondance analysis (DCA) is identical except it attempts
# to account for a well known artefact of CA known as the arch-effect 
# by detrending subsequent axes from previous axes. 
tree_dca = decorana(comm)

# Non-metric multidimenstional scaling (MDS) is unique in that you may 
# specify one of a number of different distance metrics to use. By 
# default the Bray-Curtis distance is used by metaMDS. 
tree_mds = metaMDS(comm, trymax = 5)
```


* Direct or Constrained Ordination
    - Redundancy Analysis (RDA)
    - Canonical Correspondence Analysis (CCA)
    - Hypothesis Testing
    - Model Comparison
    - Variance partitioning

```{r, error=TRUE}
rda_tree = rda(comm, env)
# the above breaks b/c we have a categorical factor in env 

# vegan requires that we write out each term if we are not going to 
# convert the factor to a dummy matrix 
rda_tree = rda(comm ~ env$utme + env$utmn + env$elev + env$tci +
               env$streamdist + env$disturb + env$beers)

rda_tree
plot(rda_tree, ylim=c(-6, 6), display=c('sp','bp'), scaling=1)

anova(rda_tree, by='margin', permutations = 10)

## variance partitioning

moisture = env[ , c('elev', 'tci', 'beers', 'streamdist')]
geog = env[ , c('utme', 'utmn')]
# because the variable disturb is a factor we need to convert it into 
# a dummy matrix using the function dummies::dummy
disturb = dummy(env$disturb)

# examine the explanatory variable of each class of variables.
varpart(comm, moisture, geog, disturb)
showvarparts(3)
```


